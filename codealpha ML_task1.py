# -*- coding: utf-8 -*-
"""codealpha task 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tr2Z4WIMZpC8K3vReu0scQcQmS7vi5VO
"""

import numpy as np
import pandas as pd

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# import basic modules
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
plt.style.use('seaborn')
pd.set_option('display.max_columns', None)

data = pd.read_csv('/content/train.csv.zip')
data.head()

data.info()

data.shape

data.describe()

data.duplicated().any()

def missing_data(df):
    miss1 = pd.DataFrame(df.isnull().sum()).reset_index()
    miss1.columns = ['columns', 'Num of Miss']
    miss2 = pd.DataFrame(df.isnull().sum()/df.shape[0]*100).reset_index()
    miss2.columns = ['columns', 'Percentage of Miss']
    miss = miss1.merge(miss2, how='inner', on='columns')
    return miss[miss['Num of Miss']!=0]

missing_data(data)

data1 = data.drop(columns=['ID','Customer_ID','Month','Name','SSN','Monthly_Inhand_Salary',
                           'Type_of_Loan','Num_of_Delayed_Payment','Credit_History_Age','Amount_invested_monthly'])

missing_data(data1)

data1.head()

data1.info()

# Deleting (-) and (_) in Column
data1['Age'] = data1['Age'].str.replace('-','')
data1['Age'] = data1['Age'].str.replace('_','')

# Deleting (-) and (_) in Column
data1['Annual_Income'] = data1['Annual_Income'].str.replace('-','')
data1['Annual_Income'] = data1['Annual_Income'].str.replace('_','')

# Deleting (-) and (_) in Column
data1['Num_of_Loan'] = data1['Num_of_Loan'].str.replace('-','')
data1['Num_of_Loan'] = data1['Num_of_Loan'].str.replace('_','')

# Deleting (-) and (_) in Column
data1['Changed_Credit_Limit'] = data1['Changed_Credit_Limit'].str.replace('-','0')
data1['Changed_Credit_Limit'] = data1['Changed_Credit_Limit'].str.replace('_','0')

# Deleting (-) and (_) in Column
data1['Outstanding_Debt'] = data1['Outstanding_Debt'].str.replace('-','')
data1['Outstanding_Debt'] = data1['Outstanding_Debt'].str.replace('_','')

# Deleting (-) and (_) in Column
data1['Monthly_Balance'] = data1['Monthly_Balance'].str.replace('-','')
data1['Monthly_Balance'] = data1['Monthly_Balance'].str.replace('_','')

# Replacing (!@9#%8) to (Unknown) in Column
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('!@9#%8','Unknown')

data1['Age'] = data1['Age'].astype(int)
data1['Annual_Income'] = data1['Annual_Income'].astype(float)
data1['Num_of_Loan'] = data1['Num_of_Loan'].astype(int)
data1['Changed_Credit_Limit'] = data1['Changed_Credit_Limit'].astype(float)
data1['Outstanding_Debt'] = data1['Outstanding_Debt'].astype(float)
data1['Monthly_Balance'] = data1['Monthly_Balance'].astype(float)

numfeat = data1[['Age', 'Annual_Income', 'Num_Bank_Accounts','Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan',
           'Delay_from_due_date', 'Changed_Credit_Limit', 'Num_Credit_Inquiries','Outstanding_Debt',
           'Credit_Utilization_Ratio','Total_EMI_per_month', 'Monthly_Balance']]

for i in numfeat.columns:
    sns.distplot(numfeat[i])
    plt.title(f'Distribution of {i}')
    plt.show()

for i in numfeat.columns:
    sns.boxplot(numfeat[i])
    plt.title(f'Distribution of {i}')
    plt.show()

# Replacing outlier of Age with Ffill
data1['Age'].where((data1['Age']<=80),np.nan, inplace=True)
data1['Age'] = data1['Age'].fillna(method='ffill')
data1

# Handling missing values with mean
data1['Monthly_Balance'] = data1['Monthly_Balance'].fillna(data1['Monthly_Balance'].mean())
data1['Num_Credit_Inquiries'] = data1['Num_Credit_Inquiries'].fillna(data1['Num_Credit_Inquiries'].mean())

# Handling missing values with ffill
data1['Occupation'] = data1['Occupation'].replace('_______', method='ffill')
data1.head()

# Handling missing values with bfill
data1['Credit_Mix'] = data1['Credit_Mix'].replace('_', method='bfill')
data1.head()

data1.groupby(['Credit_Mix']).count()[['Occupation']]

from sklearn.preprocessing import LabelEncoder
lE = LabelEncoder()

data1['Credit_Mix'] = data1['Credit_Mix'].str.replace('Bad','0')
data1['Credit_Mix'] = data1['Credit_Mix'].str.replace('Standard','1')
data1['Credit_Mix'] = data1['Credit_Mix'].str.replace('Good','2')
data1['Credit_Mix'] = data1['Credit_Mix'].astype(int)
data1.groupby(['Credit_Mix']).count()[['Occupation']]

data1['Payment_of_Min_Amount'] = lE.fit_transform(data1['Payment_of_Min_Amount'])
data1.groupby(['Payment_of_Min_Amount']).count()[['Occupation']]

data1.groupby(['Payment_Behaviour']).count()[['Occupation']]

data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('Unknown','0')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('Low_spent_Small_value_payments','1')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('Low_spent_Medium_value_payments','2')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('Low_spent_Large_value_payments','3')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('High_spent_Small_value_payments','4')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('High_spent_Medium_value_payments','5')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].str.replace('High_spent_Large_value_payments','6')
data1['Payment_Behaviour'] = data1['Payment_Behaviour'].astype(int)
data1.groupby(['Payment_Behaviour']).count()[['Occupation']]

data1.groupby(['Credit_Score']).count()[['Occupation']]

data1['Credit_Score'] = data1['Credit_Score'].str.replace('Poor','0')
data1['Credit_Score'] = data1['Credit_Score'].str.replace('Standard','1')
data1['Credit_Score'] = data1['Credit_Score'].str.replace('Good','2')
data1['Credit_Score'] = data1['Credit_Score'].astype(int)
data1.groupby(['Credit_Score']).count()[['Occupation']]

data1 = pd.get_dummies(data1, columns=['Occupation'], prefix=['Occ_'])
data1.head()

from sklearn.model_selection import train_test_split

x = data1.drop('Credit_Score', axis=1) # Independet Variable
y = data1['Credit_Score'] # Dependent Variable

x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.1, random_state=42)

x_train.shape

y_train.value_counts()

pip install catboost

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier

model_dt  = DecisionTreeClassifier()
model_rf  = RandomForestClassifier()
model_catb  = CatBoostClassifier()
model_xgb = XGBClassifier()

model_rf.fit(x_train, y_train)
model_dt.fit(x_train, y_train)
model_catb.fit(x_train, y_train)
model_xgb.fit(x_train, y_train)

y_pred_dt  = model_dt.predict(x_test)
y_pred_rf  = model_rf.predict(x_test)
y_pred_catb = model_catb.predict(x_test)
y_pred_xgb  = model_xgb.predict(x_test)

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve

# Random Forest
compare_rf = pd.DataFrame({'Actual':y_test, 'Prediction':y_pred_rf})
compare_rf = compare_rf.reset_index().drop('index',axis=1)

# Decision Tree
compare_dt = pd.DataFrame({'Actual':y_test, 'Prediction':y_pred_dt})
compare_dt = compare_dt.reset_index().drop('index',axis=1)

# CatBoost
compare_catb = pd.DataFrame({'Actual':y_test, 'Prediction':y_pred_catb.T[0]})
compare_catb = compare_catb.reset_index().drop('index',axis=1)

# XGBoost
compare_xgb = pd.DataFrame({'Actual':y_test, 'Prediction':y_pred_xgb})
compare_xgb = compare_xgb.reset_index().drop('index',axis=1)

# Random Forest
result_rf = []

for i,j in compare_rf.iterrows():
    if j['Prediction']==j['Actual']:
        if j['Prediction'] == 1:
            result_rf.append('True Positive')
        else:
            result_rf.append('True Negative')
    else:
        if j['Prediction'] == 1:
            result_rf.append('False Positive')
        else:
            result_rf.append('False Negative')

compare_rf['Result'] = result_rf
print('Random Forest')
compare_rf['Result'].value_counts()

# Decision Tree
result_dt = []

for i,j in compare_dt.iterrows():
    if j['Prediction']==j['Actual']:
        if j['Prediction'] == 1:
            result_dt.append('True Positive')
        else:
            result_dt.append('True Negative')
    else:
        if j['Prediction'] == 1:
            result_dt.append('False Positive')
        else:
            result_dt.append('False Negative')

compare_dt['Result'] = result_dt
compare_dt['Result'].value_counts()

# CatBoost
result_catb = []

for i,j in compare_catb.iterrows():
    if j['Prediction']==j['Actual']:
        if j['Prediction'] == 1:
            result_catb.append('True Positive')
        else:
            result_catb.append('True Negative')
    else:
        if j['Prediction'] == 1:
            result_catb.append('False Positive')
        else:
            result_catb.append('False Negative')

compare_catb['Result'] = result_catb
print('Random Forest')
compare_catb['Result'].value_counts()

# XGBoost Classifier
result_xgb = []

for i,j in compare_xgb.iterrows():
    if j['Prediction']==j['Actual']:
        if j['Prediction'] == 1:
            result_xgb.append('True Positive')
        else:
            result_xgb.append('True Negative')
    else:
        if j['Prediction'] == 1:
            result_xgb.append('False Positive')
        else:
            result_xgb.append('False Negative')

compare_xgb['Result'] = result_xgb
print('XGBoost Classifier')
compare_xgb['Result'].value_counts()

sns.heatmap(confusion_matrix(y_test,y_pred_rf), annot=True)
plt.ylabel('Actual')
plt.xlabel('Prediction')
print(classification_report(y_test,y_pred_rf))

sns.heatmap(confusion_matrix(y_test,y_pred_dt), annot=True)
plt.ylabel('Actual')
plt.xlabel('Prediction')
print(classification_report(y_test,y_pred_dt))

sns.heatmap(confusion_matrix(y_test,y_pred_catb), annot=True)
plt.ylabel('Actual')
plt.xlabel('Prediction')
print(classification_report(y_test,y_pred_catb))

sns.heatmap(confusion_matrix(y_test,y_pred_xgb), annot=True)
plt.ylabel('Actual')
plt.xlabel('Prediction')
print(classification_report(y_test,y_pred_xgb))

accuracy, precision, recall, f1 = [],[],[],[]
predictions = [y_pred_rf, y_pred_dt, y_pred_catb,y_pred_xgb]

for pred in predictions:
    accuracy.append(accuracy_score(y_test, pred,)*100)
    precision.append(precision_score(y_test, pred, average='macro')*100)
    recall.append(recall_score(y_test, pred, average='macro')*100)
    f1.append(f1_score(y_test, pred, average='macro')*100)

compare = pd.DataFrame({'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'F1_Score': f1},
                        index=['Random Forest','Decision Tree','CatBoost','XGBoost'])### Classification Report
compare.sort_values('Accuracy', ascending=False)